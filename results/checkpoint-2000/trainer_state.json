{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.1376564277588168,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005688282138794084,
      "grad_norm": 1.1840522289276123,
      "learning_rate": 4.9905195297686766e-05,
      "loss": 3.6424,
      "step": 10
    },
    {
      "epoch": 0.011376564277588168,
      "grad_norm": 1.1066473722457886,
      "learning_rate": 4.9810390595373535e-05,
      "loss": 3.8112,
      "step": 20
    },
    {
      "epoch": 0.017064846416382253,
      "grad_norm": 1.4943959712982178,
      "learning_rate": 4.97155858930603e-05,
      "loss": 3.7862,
      "step": 30
    },
    {
      "epoch": 0.022753128555176336,
      "grad_norm": 1.267715573310852,
      "learning_rate": 4.962078119074706e-05,
      "loss": 3.2721,
      "step": 40
    },
    {
      "epoch": 0.02844141069397042,
      "grad_norm": 1.2657086849212646,
      "learning_rate": 4.952597648843383e-05,
      "loss": 3.3949,
      "step": 50
    },
    {
      "epoch": 0.034129692832764506,
      "grad_norm": 1.1803443431854248,
      "learning_rate": 4.9431171786120595e-05,
      "loss": 3.2137,
      "step": 60
    },
    {
      "epoch": 0.03981797497155859,
      "grad_norm": 1.294848084449768,
      "learning_rate": 4.933636708380736e-05,
      "loss": 3.1255,
      "step": 70
    },
    {
      "epoch": 0.04550625711035267,
      "grad_norm": 1.0492851734161377,
      "learning_rate": 4.924156238149412e-05,
      "loss": 3.0084,
      "step": 80
    },
    {
      "epoch": 0.051194539249146756,
      "grad_norm": 1.2727558612823486,
      "learning_rate": 4.914675767918089e-05,
      "loss": 3.0637,
      "step": 90
    },
    {
      "epoch": 0.05688282138794084,
      "grad_norm": 1.1558613777160645,
      "learning_rate": 4.9051952976867654e-05,
      "loss": 3.2633,
      "step": 100
    },
    {
      "epoch": 0.06257110352673492,
      "grad_norm": 1.4295926094055176,
      "learning_rate": 4.895714827455442e-05,
      "loss": 3.2033,
      "step": 110
    },
    {
      "epoch": 0.06825938566552901,
      "grad_norm": 1.1814738512039185,
      "learning_rate": 4.886234357224119e-05,
      "loss": 3.1245,
      "step": 120
    },
    {
      "epoch": 0.07394766780432309,
      "grad_norm": 1.2840455770492554,
      "learning_rate": 4.876753886992795e-05,
      "loss": 2.9629,
      "step": 130
    },
    {
      "epoch": 0.07963594994311718,
      "grad_norm": 1.1700204610824585,
      "learning_rate": 4.8672734167614714e-05,
      "loss": 3.2956,
      "step": 140
    },
    {
      "epoch": 0.08532423208191127,
      "grad_norm": 1.3060708045959473,
      "learning_rate": 4.8577929465301484e-05,
      "loss": 2.8537,
      "step": 150
    },
    {
      "epoch": 0.09101251422070535,
      "grad_norm": 1.465187668800354,
      "learning_rate": 4.848312476298825e-05,
      "loss": 3.0538,
      "step": 160
    },
    {
      "epoch": 0.09670079635949944,
      "grad_norm": 1.3654285669326782,
      "learning_rate": 4.838832006067501e-05,
      "loss": 3.3101,
      "step": 170
    },
    {
      "epoch": 0.10238907849829351,
      "grad_norm": 1.361220359802246,
      "learning_rate": 4.829351535836178e-05,
      "loss": 2.9929,
      "step": 180
    },
    {
      "epoch": 0.1080773606370876,
      "grad_norm": 1.4478404521942139,
      "learning_rate": 4.819871065604854e-05,
      "loss": 2.963,
      "step": 190
    },
    {
      "epoch": 0.11376564277588168,
      "grad_norm": 1.507630705833435,
      "learning_rate": 4.8103905953735306e-05,
      "loss": 3.0085,
      "step": 200
    },
    {
      "epoch": 0.11945392491467577,
      "grad_norm": 1.2725622653961182,
      "learning_rate": 4.8009101251422076e-05,
      "loss": 2.9325,
      "step": 210
    },
    {
      "epoch": 0.12514220705346984,
      "grad_norm": 1.3288112878799438,
      "learning_rate": 4.791429654910884e-05,
      "loss": 2.9901,
      "step": 220
    },
    {
      "epoch": 0.13083048919226395,
      "grad_norm": 1.39552903175354,
      "learning_rate": 4.78194918467956e-05,
      "loss": 2.8743,
      "step": 230
    },
    {
      "epoch": 0.13651877133105803,
      "grad_norm": 1.4048992395401,
      "learning_rate": 4.7724687144482366e-05,
      "loss": 2.8956,
      "step": 240
    },
    {
      "epoch": 0.1422070534698521,
      "grad_norm": 1.430892825126648,
      "learning_rate": 4.7629882442169135e-05,
      "loss": 2.937,
      "step": 250
    },
    {
      "epoch": 0.14789533560864618,
      "grad_norm": 1.3461686372756958,
      "learning_rate": 4.75350777398559e-05,
      "loss": 3.1078,
      "step": 260
    },
    {
      "epoch": 0.15358361774744028,
      "grad_norm": 1.4490413665771484,
      "learning_rate": 4.744027303754267e-05,
      "loss": 2.8674,
      "step": 270
    },
    {
      "epoch": 0.15927189988623436,
      "grad_norm": 1.6700984239578247,
      "learning_rate": 4.734546833522943e-05,
      "loss": 3.0276,
      "step": 280
    },
    {
      "epoch": 0.16496018202502843,
      "grad_norm": 1.4937001466751099,
      "learning_rate": 4.7250663632916195e-05,
      "loss": 2.9627,
      "step": 290
    },
    {
      "epoch": 0.17064846416382254,
      "grad_norm": 1.4727190732955933,
      "learning_rate": 4.715585893060296e-05,
      "loss": 2.8063,
      "step": 300
    },
    {
      "epoch": 0.17633674630261661,
      "grad_norm": 1.3600003719329834,
      "learning_rate": 4.706105422828973e-05,
      "loss": 2.6026,
      "step": 310
    },
    {
      "epoch": 0.1820250284414107,
      "grad_norm": 1.5846573114395142,
      "learning_rate": 4.696624952597649e-05,
      "loss": 2.6471,
      "step": 320
    },
    {
      "epoch": 0.18771331058020477,
      "grad_norm": 1.605607509613037,
      "learning_rate": 4.6871444823663254e-05,
      "loss": 2.7449,
      "step": 330
    },
    {
      "epoch": 0.19340159271899887,
      "grad_norm": 1.6549433469772339,
      "learning_rate": 4.6776640121350024e-05,
      "loss": 2.7424,
      "step": 340
    },
    {
      "epoch": 0.19908987485779295,
      "grad_norm": 1.4639432430267334,
      "learning_rate": 4.668183541903679e-05,
      "loss": 2.4782,
      "step": 350
    },
    {
      "epoch": 0.20477815699658702,
      "grad_norm": 1.5364162921905518,
      "learning_rate": 4.658703071672355e-05,
      "loss": 2.8291,
      "step": 360
    },
    {
      "epoch": 0.21046643913538113,
      "grad_norm": 1.5868504047393799,
      "learning_rate": 4.649222601441032e-05,
      "loss": 2.7958,
      "step": 370
    },
    {
      "epoch": 0.2161547212741752,
      "grad_norm": 1.955855131149292,
      "learning_rate": 4.6397421312097084e-05,
      "loss": 2.9948,
      "step": 380
    },
    {
      "epoch": 0.22184300341296928,
      "grad_norm": 1.6161415576934814,
      "learning_rate": 4.630261660978385e-05,
      "loss": 2.807,
      "step": 390
    },
    {
      "epoch": 0.22753128555176336,
      "grad_norm": 1.718761920928955,
      "learning_rate": 4.620781190747061e-05,
      "loss": 2.7385,
      "step": 400
    },
    {
      "epoch": 0.23321956769055746,
      "grad_norm": 1.5597854852676392,
      "learning_rate": 4.611300720515738e-05,
      "loss": 2.7961,
      "step": 410
    },
    {
      "epoch": 0.23890784982935154,
      "grad_norm": 1.6261762380599976,
      "learning_rate": 4.601820250284414e-05,
      "loss": 3.0245,
      "step": 420
    },
    {
      "epoch": 0.2445961319681456,
      "grad_norm": 1.7425310611724854,
      "learning_rate": 4.592339780053091e-05,
      "loss": 2.9694,
      "step": 430
    },
    {
      "epoch": 0.2502844141069397,
      "grad_norm": 1.6412144899368286,
      "learning_rate": 4.5828593098217676e-05,
      "loss": 2.6596,
      "step": 440
    },
    {
      "epoch": 0.25597269624573377,
      "grad_norm": 1.6944148540496826,
      "learning_rate": 4.573378839590444e-05,
      "loss": 2.5412,
      "step": 450
    },
    {
      "epoch": 0.2616609783845279,
      "grad_norm": 1.6538231372833252,
      "learning_rate": 4.56389836935912e-05,
      "loss": 2.5387,
      "step": 460
    },
    {
      "epoch": 0.267349260523322,
      "grad_norm": 1.5119332075119019,
      "learning_rate": 4.554417899127797e-05,
      "loss": 2.8844,
      "step": 470
    },
    {
      "epoch": 0.27303754266211605,
      "grad_norm": 1.8447022438049316,
      "learning_rate": 4.5449374288964735e-05,
      "loss": 2.8867,
      "step": 480
    },
    {
      "epoch": 0.2787258248009101,
      "grad_norm": 1.398255705833435,
      "learning_rate": 4.53545695866515e-05,
      "loss": 2.718,
      "step": 490
    },
    {
      "epoch": 0.2844141069397042,
      "grad_norm": 1.6721446514129639,
      "learning_rate": 4.525976488433826e-05,
      "loss": 2.8587,
      "step": 500
    },
    {
      "epoch": 0.2901023890784983,
      "grad_norm": 1.638363242149353,
      "learning_rate": 4.516496018202503e-05,
      "loss": 2.8962,
      "step": 510
    },
    {
      "epoch": 0.29579067121729236,
      "grad_norm": 1.9011434316635132,
      "learning_rate": 4.5070155479711795e-05,
      "loss": 2.7146,
      "step": 520
    },
    {
      "epoch": 0.3014789533560865,
      "grad_norm": 1.7658836841583252,
      "learning_rate": 4.4975350777398565e-05,
      "loss": 2.609,
      "step": 530
    },
    {
      "epoch": 0.30716723549488056,
      "grad_norm": 1.7144818305969238,
      "learning_rate": 4.488054607508533e-05,
      "loss": 2.711,
      "step": 540
    },
    {
      "epoch": 0.31285551763367464,
      "grad_norm": 1.695155143737793,
      "learning_rate": 4.478574137277209e-05,
      "loss": 2.5638,
      "step": 550
    },
    {
      "epoch": 0.3185437997724687,
      "grad_norm": 1.5457080602645874,
      "learning_rate": 4.4690936670458854e-05,
      "loss": 2.6847,
      "step": 560
    },
    {
      "epoch": 0.3242320819112628,
      "grad_norm": 1.672538161277771,
      "learning_rate": 4.4596131968145624e-05,
      "loss": 2.6473,
      "step": 570
    },
    {
      "epoch": 0.32992036405005687,
      "grad_norm": 1.5833854675292969,
      "learning_rate": 4.450132726583239e-05,
      "loss": 2.645,
      "step": 580
    },
    {
      "epoch": 0.33560864618885095,
      "grad_norm": 1.7899351119995117,
      "learning_rate": 4.440652256351916e-05,
      "loss": 2.7977,
      "step": 590
    },
    {
      "epoch": 0.3412969283276451,
      "grad_norm": 1.5812206268310547,
      "learning_rate": 4.431171786120592e-05,
      "loss": 2.4875,
      "step": 600
    },
    {
      "epoch": 0.34698521046643915,
      "grad_norm": 1.52481210231781,
      "learning_rate": 4.4216913158892684e-05,
      "loss": 2.5622,
      "step": 610
    },
    {
      "epoch": 0.35267349260523323,
      "grad_norm": 1.5895038843154907,
      "learning_rate": 4.412210845657945e-05,
      "loss": 2.5312,
      "step": 620
    },
    {
      "epoch": 0.3583617747440273,
      "grad_norm": 1.4821257591247559,
      "learning_rate": 4.402730375426622e-05,
      "loss": 2.9617,
      "step": 630
    },
    {
      "epoch": 0.3640500568828214,
      "grad_norm": 1.8058371543884277,
      "learning_rate": 4.393249905195298e-05,
      "loss": 2.5655,
      "step": 640
    },
    {
      "epoch": 0.36973833902161546,
      "grad_norm": 1.7320345640182495,
      "learning_rate": 4.383769434963974e-05,
      "loss": 2.6786,
      "step": 650
    },
    {
      "epoch": 0.37542662116040953,
      "grad_norm": 1.8239275217056274,
      "learning_rate": 4.3742889647326506e-05,
      "loss": 2.6282,
      "step": 660
    },
    {
      "epoch": 0.38111490329920367,
      "grad_norm": 1.6258221864700317,
      "learning_rate": 4.3648084945013276e-05,
      "loss": 2.4673,
      "step": 670
    },
    {
      "epoch": 0.38680318543799774,
      "grad_norm": 1.7344262599945068,
      "learning_rate": 4.355328024270004e-05,
      "loss": 2.6889,
      "step": 680
    },
    {
      "epoch": 0.3924914675767918,
      "grad_norm": 1.7352560758590698,
      "learning_rate": 4.345847554038681e-05,
      "loss": 2.6415,
      "step": 690
    },
    {
      "epoch": 0.3981797497155859,
      "grad_norm": 1.6515235900878906,
      "learning_rate": 4.336367083807357e-05,
      "loss": 2.6934,
      "step": 700
    },
    {
      "epoch": 0.40386803185437997,
      "grad_norm": 1.7131084203720093,
      "learning_rate": 4.3268866135760335e-05,
      "loss": 2.5069,
      "step": 710
    },
    {
      "epoch": 0.40955631399317405,
      "grad_norm": 2.0305275917053223,
      "learning_rate": 4.31740614334471e-05,
      "loss": 2.604,
      "step": 720
    },
    {
      "epoch": 0.4152445961319681,
      "grad_norm": 4.964780330657959,
      "learning_rate": 4.307925673113387e-05,
      "loss": 2.9609,
      "step": 730
    },
    {
      "epoch": 0.42093287827076226,
      "grad_norm": 1.7239235639572144,
      "learning_rate": 4.298445202882063e-05,
      "loss": 2.993,
      "step": 740
    },
    {
      "epoch": 0.42662116040955633,
      "grad_norm": 1.4889949560165405,
      "learning_rate": 4.28896473265074e-05,
      "loss": 2.5141,
      "step": 750
    },
    {
      "epoch": 0.4323094425483504,
      "grad_norm": 1.940831184387207,
      "learning_rate": 4.2794842624194165e-05,
      "loss": 2.8515,
      "step": 760
    },
    {
      "epoch": 0.4379977246871445,
      "grad_norm": 1.6206830739974976,
      "learning_rate": 4.270003792188093e-05,
      "loss": 2.7304,
      "step": 770
    },
    {
      "epoch": 0.44368600682593856,
      "grad_norm": 1.480495572090149,
      "learning_rate": 4.260523321956769e-05,
      "loss": 2.5623,
      "step": 780
    },
    {
      "epoch": 0.44937428896473264,
      "grad_norm": 1.7047971487045288,
      "learning_rate": 4.251042851725446e-05,
      "loss": 2.5435,
      "step": 790
    },
    {
      "epoch": 0.4550625711035267,
      "grad_norm": 1.8817979097366333,
      "learning_rate": 4.2415623814941224e-05,
      "loss": 2.6949,
      "step": 800
    },
    {
      "epoch": 0.46075085324232085,
      "grad_norm": 1.8404712677001953,
      "learning_rate": 4.2320819112627994e-05,
      "loss": 2.4677,
      "step": 810
    },
    {
      "epoch": 0.4664391353811149,
      "grad_norm": 1.7871347665786743,
      "learning_rate": 4.222601441031475e-05,
      "loss": 2.8546,
      "step": 820
    },
    {
      "epoch": 0.472127417519909,
      "grad_norm": 1.636745572090149,
      "learning_rate": 4.213120970800152e-05,
      "loss": 2.6887,
      "step": 830
    },
    {
      "epoch": 0.4778156996587031,
      "grad_norm": 1.7996717691421509,
      "learning_rate": 4.2036405005688284e-05,
      "loss": 2.581,
      "step": 840
    },
    {
      "epoch": 0.48350398179749715,
      "grad_norm": 1.8387221097946167,
      "learning_rate": 4.1941600303375053e-05,
      "loss": 2.9209,
      "step": 850
    },
    {
      "epoch": 0.4891922639362912,
      "grad_norm": 1.9100065231323242,
      "learning_rate": 4.184679560106182e-05,
      "loss": 2.4763,
      "step": 860
    },
    {
      "epoch": 0.4948805460750853,
      "grad_norm": 1.6824121475219727,
      "learning_rate": 4.175199089874858e-05,
      "loss": 2.8989,
      "step": 870
    },
    {
      "epoch": 0.5005688282138794,
      "grad_norm": 1.6961688995361328,
      "learning_rate": 4.165718619643534e-05,
      "loss": 2.6392,
      "step": 880
    },
    {
      "epoch": 0.5062571103526735,
      "grad_norm": 1.7537975311279297,
      "learning_rate": 4.156238149412211e-05,
      "loss": 2.662,
      "step": 890
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 1.7135173082351685,
      "learning_rate": 4.1467576791808876e-05,
      "loss": 2.7814,
      "step": 900
    },
    {
      "epoch": 0.5176336746302617,
      "grad_norm": 1.93651282787323,
      "learning_rate": 4.1372772089495646e-05,
      "loss": 2.5821,
      "step": 910
    },
    {
      "epoch": 0.5233219567690558,
      "grad_norm": 1.6874661445617676,
      "learning_rate": 4.12779673871824e-05,
      "loss": 2.6731,
      "step": 920
    },
    {
      "epoch": 0.5290102389078498,
      "grad_norm": 1.9278578758239746,
      "learning_rate": 4.118316268486917e-05,
      "loss": 2.4643,
      "step": 930
    },
    {
      "epoch": 0.534698521046644,
      "grad_norm": 2.033489465713501,
      "learning_rate": 4.1088357982555935e-05,
      "loss": 2.6064,
      "step": 940
    },
    {
      "epoch": 0.540386803185438,
      "grad_norm": 1.6602821350097656,
      "learning_rate": 4.0993553280242705e-05,
      "loss": 2.6248,
      "step": 950
    },
    {
      "epoch": 0.5460750853242321,
      "grad_norm": 1.8129944801330566,
      "learning_rate": 4.089874857792947e-05,
      "loss": 2.6789,
      "step": 960
    },
    {
      "epoch": 0.5517633674630261,
      "grad_norm": 1.7531323432922363,
      "learning_rate": 4.080394387561624e-05,
      "loss": 2.6559,
      "step": 970
    },
    {
      "epoch": 0.5574516496018203,
      "grad_norm": 1.7522550821304321,
      "learning_rate": 4.0709139173302995e-05,
      "loss": 2.6144,
      "step": 980
    },
    {
      "epoch": 0.5631399317406144,
      "grad_norm": 1.7209596633911133,
      "learning_rate": 4.0614334470989765e-05,
      "loss": 2.456,
      "step": 990
    },
    {
      "epoch": 0.5688282138794084,
      "grad_norm": 1.9101529121398926,
      "learning_rate": 4.051952976867653e-05,
      "loss": 2.5947,
      "step": 1000
    },
    {
      "epoch": 0.5745164960182025,
      "grad_norm": 1.9122183322906494,
      "learning_rate": 4.04247250663633e-05,
      "loss": 2.7778,
      "step": 1010
    },
    {
      "epoch": 0.5802047781569966,
      "grad_norm": 1.9505305290222168,
      "learning_rate": 4.032992036405006e-05,
      "loss": 2.6444,
      "step": 1020
    },
    {
      "epoch": 0.5858930602957907,
      "grad_norm": 1.8624544143676758,
      "learning_rate": 4.0235115661736824e-05,
      "loss": 2.6672,
      "step": 1030
    },
    {
      "epoch": 0.5915813424345847,
      "grad_norm": 1.763140082359314,
      "learning_rate": 4.014031095942359e-05,
      "loss": 2.4806,
      "step": 1040
    },
    {
      "epoch": 0.5972696245733788,
      "grad_norm": 1.7116060256958008,
      "learning_rate": 4.004550625711036e-05,
      "loss": 2.7785,
      "step": 1050
    },
    {
      "epoch": 0.602957906712173,
      "grad_norm": 1.7877191305160522,
      "learning_rate": 3.995070155479712e-05,
      "loss": 2.5715,
      "step": 1060
    },
    {
      "epoch": 0.608646188850967,
      "grad_norm": 1.8293726444244385,
      "learning_rate": 3.985589685248389e-05,
      "loss": 2.434,
      "step": 1070
    },
    {
      "epoch": 0.6143344709897611,
      "grad_norm": 2.2948577404022217,
      "learning_rate": 3.976109215017065e-05,
      "loss": 2.5195,
      "step": 1080
    },
    {
      "epoch": 0.6200227531285551,
      "grad_norm": 1.8122014999389648,
      "learning_rate": 3.966628744785742e-05,
      "loss": 2.4367,
      "step": 1090
    },
    {
      "epoch": 0.6257110352673493,
      "grad_norm": 1.742236852645874,
      "learning_rate": 3.957148274554418e-05,
      "loss": 2.6192,
      "step": 1100
    },
    {
      "epoch": 0.6313993174061433,
      "grad_norm": 2.0351133346557617,
      "learning_rate": 3.947667804323095e-05,
      "loss": 2.3937,
      "step": 1110
    },
    {
      "epoch": 0.6370875995449374,
      "grad_norm": 1.8651484251022339,
      "learning_rate": 3.938187334091771e-05,
      "loss": 2.6671,
      "step": 1120
    },
    {
      "epoch": 0.6427758816837316,
      "grad_norm": 1.8781979084014893,
      "learning_rate": 3.9287068638604476e-05,
      "loss": 2.6756,
      "step": 1130
    },
    {
      "epoch": 0.6484641638225256,
      "grad_norm": 2.0190937519073486,
      "learning_rate": 3.919226393629124e-05,
      "loss": 2.5421,
      "step": 1140
    },
    {
      "epoch": 0.6541524459613197,
      "grad_norm": 1.8050549030303955,
      "learning_rate": 3.909745923397801e-05,
      "loss": 2.6385,
      "step": 1150
    },
    {
      "epoch": 0.6598407281001137,
      "grad_norm": 2.2315075397491455,
      "learning_rate": 3.900265453166477e-05,
      "loss": 2.5708,
      "step": 1160
    },
    {
      "epoch": 0.6655290102389079,
      "grad_norm": 1.8540414571762085,
      "learning_rate": 3.890784982935154e-05,
      "loss": 2.435,
      "step": 1170
    },
    {
      "epoch": 0.6712172923777019,
      "grad_norm": 1.91741943359375,
      "learning_rate": 3.8813045127038305e-05,
      "loss": 2.6624,
      "step": 1180
    },
    {
      "epoch": 0.676905574516496,
      "grad_norm": 2.1156845092773438,
      "learning_rate": 3.871824042472507e-05,
      "loss": 2.5729,
      "step": 1190
    },
    {
      "epoch": 0.6825938566552902,
      "grad_norm": 1.7722679376602173,
      "learning_rate": 3.862343572241183e-05,
      "loss": 2.6359,
      "step": 1200
    },
    {
      "epoch": 0.6882821387940842,
      "grad_norm": 1.753456473350525,
      "learning_rate": 3.85286310200986e-05,
      "loss": 2.7055,
      "step": 1210
    },
    {
      "epoch": 0.6939704209328783,
      "grad_norm": 2.026064395904541,
      "learning_rate": 3.8433826317785365e-05,
      "loss": 3.0982,
      "step": 1220
    },
    {
      "epoch": 0.6996587030716723,
      "grad_norm": 1.8876149654388428,
      "learning_rate": 3.8339021615472135e-05,
      "loss": 2.6649,
      "step": 1230
    },
    {
      "epoch": 0.7053469852104665,
      "grad_norm": 1.433695912361145,
      "learning_rate": 3.824421691315889e-05,
      "loss": 2.6315,
      "step": 1240
    },
    {
      "epoch": 0.7110352673492605,
      "grad_norm": 1.8294188976287842,
      "learning_rate": 3.814941221084566e-05,
      "loss": 2.3983,
      "step": 1250
    },
    {
      "epoch": 0.7167235494880546,
      "grad_norm": 1.8802483081817627,
      "learning_rate": 3.8054607508532424e-05,
      "loss": 2.5432,
      "step": 1260
    },
    {
      "epoch": 0.7224118316268487,
      "grad_norm": 1.991202473640442,
      "learning_rate": 3.7959802806219194e-05,
      "loss": 2.6204,
      "step": 1270
    },
    {
      "epoch": 0.7281001137656428,
      "grad_norm": 1.7331645488739014,
      "learning_rate": 3.786499810390596e-05,
      "loss": 2.5238,
      "step": 1280
    },
    {
      "epoch": 0.7337883959044369,
      "grad_norm": 2.018613815307617,
      "learning_rate": 3.777019340159272e-05,
      "loss": 2.3684,
      "step": 1290
    },
    {
      "epoch": 0.7394766780432309,
      "grad_norm": 1.7485496997833252,
      "learning_rate": 3.7675388699279484e-05,
      "loss": 2.6712,
      "step": 1300
    },
    {
      "epoch": 0.745164960182025,
      "grad_norm": 1.8774378299713135,
      "learning_rate": 3.7580583996966253e-05,
      "loss": 2.4982,
      "step": 1310
    },
    {
      "epoch": 0.7508532423208191,
      "grad_norm": 1.839454174041748,
      "learning_rate": 3.7485779294653017e-05,
      "loss": 2.6664,
      "step": 1320
    },
    {
      "epoch": 0.7565415244596132,
      "grad_norm": 1.7456144094467163,
      "learning_rate": 3.7390974592339787e-05,
      "loss": 2.6015,
      "step": 1330
    },
    {
      "epoch": 0.7622298065984073,
      "grad_norm": 1.8833580017089844,
      "learning_rate": 3.729616989002654e-05,
      "loss": 2.4818,
      "step": 1340
    },
    {
      "epoch": 0.7679180887372014,
      "grad_norm": 2.1328296661376953,
      "learning_rate": 3.720136518771331e-05,
      "loss": 2.2225,
      "step": 1350
    },
    {
      "epoch": 0.7736063708759955,
      "grad_norm": 1.946182370185852,
      "learning_rate": 3.7106560485400076e-05,
      "loss": 2.4492,
      "step": 1360
    },
    {
      "epoch": 0.7792946530147895,
      "grad_norm": 1.7089473009109497,
      "learning_rate": 3.7011755783086846e-05,
      "loss": 2.6642,
      "step": 1370
    },
    {
      "epoch": 0.7849829351535836,
      "grad_norm": 1.9546905755996704,
      "learning_rate": 3.691695108077361e-05,
      "loss": 2.5189,
      "step": 1380
    },
    {
      "epoch": 0.7906712172923777,
      "grad_norm": 1.945075511932373,
      "learning_rate": 3.682214637846038e-05,
      "loss": 2.6082,
      "step": 1390
    },
    {
      "epoch": 0.7963594994311718,
      "grad_norm": 2.08254075050354,
      "learning_rate": 3.6727341676147135e-05,
      "loss": 2.5183,
      "step": 1400
    },
    {
      "epoch": 0.8020477815699659,
      "grad_norm": 1.7358146905899048,
      "learning_rate": 3.6632536973833905e-05,
      "loss": 2.3719,
      "step": 1410
    },
    {
      "epoch": 0.8077360637087599,
      "grad_norm": 2.394360303878784,
      "learning_rate": 3.653773227152067e-05,
      "loss": 2.6006,
      "step": 1420
    },
    {
      "epoch": 0.8134243458475541,
      "grad_norm": 2.1957759857177734,
      "learning_rate": 3.644292756920744e-05,
      "loss": 2.7562,
      "step": 1430
    },
    {
      "epoch": 0.8191126279863481,
      "grad_norm": 1.7685041427612305,
      "learning_rate": 3.63481228668942e-05,
      "loss": 2.2255,
      "step": 1440
    },
    {
      "epoch": 0.8248009101251422,
      "grad_norm": 1.9511439800262451,
      "learning_rate": 3.6253318164580965e-05,
      "loss": 2.5052,
      "step": 1450
    },
    {
      "epoch": 0.8304891922639362,
      "grad_norm": 1.850136399269104,
      "learning_rate": 3.615851346226773e-05,
      "loss": 2.4598,
      "step": 1460
    },
    {
      "epoch": 0.8361774744027304,
      "grad_norm": 2.1229028701782227,
      "learning_rate": 3.60637087599545e-05,
      "loss": 2.6601,
      "step": 1470
    },
    {
      "epoch": 0.8418657565415245,
      "grad_norm": 2.146454334259033,
      "learning_rate": 3.596890405764126e-05,
      "loss": 2.6687,
      "step": 1480
    },
    {
      "epoch": 0.8475540386803185,
      "grad_norm": 2.2313992977142334,
      "learning_rate": 3.587409935532803e-05,
      "loss": 2.6986,
      "step": 1490
    },
    {
      "epoch": 0.8532423208191127,
      "grad_norm": 1.8351048231124878,
      "learning_rate": 3.577929465301479e-05,
      "loss": 2.7693,
      "step": 1500
    },
    {
      "epoch": 0.8589306029579067,
      "grad_norm": 2.0515499114990234,
      "learning_rate": 3.568448995070156e-05,
      "loss": 2.4373,
      "step": 1510
    },
    {
      "epoch": 0.8646188850967008,
      "grad_norm": 1.9850878715515137,
      "learning_rate": 3.558968524838832e-05,
      "loss": 2.4065,
      "step": 1520
    },
    {
      "epoch": 0.8703071672354948,
      "grad_norm": 1.9145864248275757,
      "learning_rate": 3.549488054607509e-05,
      "loss": 2.5829,
      "step": 1530
    },
    {
      "epoch": 0.875995449374289,
      "grad_norm": 1.978048324584961,
      "learning_rate": 3.5400075843761853e-05,
      "loss": 2.5836,
      "step": 1540
    },
    {
      "epoch": 0.8816837315130831,
      "grad_norm": 1.8269827365875244,
      "learning_rate": 3.5305271141448617e-05,
      "loss": 2.4084,
      "step": 1550
    },
    {
      "epoch": 0.8873720136518771,
      "grad_norm": 1.7206259965896606,
      "learning_rate": 3.521046643913538e-05,
      "loss": 2.6275,
      "step": 1560
    },
    {
      "epoch": 0.8930602957906713,
      "grad_norm": 1.9114774465560913,
      "learning_rate": 3.511566173682215e-05,
      "loss": 2.5462,
      "step": 1570
    },
    {
      "epoch": 0.8987485779294653,
      "grad_norm": 2.02711820602417,
      "learning_rate": 3.502085703450891e-05,
      "loss": 2.5333,
      "step": 1580
    },
    {
      "epoch": 0.9044368600682594,
      "grad_norm": 2.0332956314086914,
      "learning_rate": 3.492605233219568e-05,
      "loss": 3.029,
      "step": 1590
    },
    {
      "epoch": 0.9101251422070534,
      "grad_norm": 1.9734388589859009,
      "learning_rate": 3.4831247629882446e-05,
      "loss": 2.4359,
      "step": 1600
    },
    {
      "epoch": 0.9158134243458476,
      "grad_norm": 1.786482334136963,
      "learning_rate": 3.473644292756921e-05,
      "loss": 2.4943,
      "step": 1610
    },
    {
      "epoch": 0.9215017064846417,
      "grad_norm": 1.8860944509506226,
      "learning_rate": 3.464163822525597e-05,
      "loss": 2.6086,
      "step": 1620
    },
    {
      "epoch": 0.9271899886234357,
      "grad_norm": 2.1260323524475098,
      "learning_rate": 3.454683352294274e-05,
      "loss": 2.5186,
      "step": 1630
    },
    {
      "epoch": 0.9328782707622298,
      "grad_norm": 2.037703275680542,
      "learning_rate": 3.4452028820629505e-05,
      "loss": 2.5173,
      "step": 1640
    },
    {
      "epoch": 0.9385665529010239,
      "grad_norm": 1.8920955657958984,
      "learning_rate": 3.4357224118316275e-05,
      "loss": 2.4857,
      "step": 1650
    },
    {
      "epoch": 0.944254835039818,
      "grad_norm": 2.0456297397613525,
      "learning_rate": 3.426241941600303e-05,
      "loss": 2.5414,
      "step": 1660
    },
    {
      "epoch": 0.949943117178612,
      "grad_norm": 1.9163354635238647,
      "learning_rate": 3.41676147136898e-05,
      "loss": 2.5019,
      "step": 1670
    },
    {
      "epoch": 0.9556313993174061,
      "grad_norm": 1.8684539794921875,
      "learning_rate": 3.4072810011376565e-05,
      "loss": 2.5456,
      "step": 1680
    },
    {
      "epoch": 0.9613196814562003,
      "grad_norm": 1.9421676397323608,
      "learning_rate": 3.3978005309063335e-05,
      "loss": 2.465,
      "step": 1690
    },
    {
      "epoch": 0.9670079635949943,
      "grad_norm": 2.090778112411499,
      "learning_rate": 3.38832006067501e-05,
      "loss": 2.6348,
      "step": 1700
    },
    {
      "epoch": 0.9726962457337884,
      "grad_norm": 2.111792802810669,
      "learning_rate": 3.378839590443686e-05,
      "loss": 2.4232,
      "step": 1710
    },
    {
      "epoch": 0.9783845278725825,
      "grad_norm": 1.8758773803710938,
      "learning_rate": 3.3693591202123624e-05,
      "loss": 2.7824,
      "step": 1720
    },
    {
      "epoch": 0.9840728100113766,
      "grad_norm": 1.8722748756408691,
      "learning_rate": 3.3598786499810394e-05,
      "loss": 2.3118,
      "step": 1730
    },
    {
      "epoch": 0.9897610921501706,
      "grad_norm": 2.03971529006958,
      "learning_rate": 3.350398179749716e-05,
      "loss": 2.8389,
      "step": 1740
    },
    {
      "epoch": 0.9954493742889647,
      "grad_norm": 2.004847764968872,
      "learning_rate": 3.340917709518393e-05,
      "loss": 2.6489,
      "step": 1750
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.7008252143859863,
      "eval_runtime": 84.9308,
      "eval_samples_per_second": 1.177,
      "eval_steps_per_second": 0.294,
      "step": 1758
    },
    {
      "epoch": 1.0011376564277588,
      "grad_norm": 1.921654224395752,
      "learning_rate": 3.3314372392870683e-05,
      "loss": 2.6077,
      "step": 1760
    },
    {
      "epoch": 1.006825938566553,
      "grad_norm": 2.000149726867676,
      "learning_rate": 3.3219567690557453e-05,
      "loss": 2.5661,
      "step": 1770
    },
    {
      "epoch": 1.012514220705347,
      "grad_norm": 1.917399287223816,
      "learning_rate": 3.3124762988244217e-05,
      "loss": 2.5883,
      "step": 1780
    },
    {
      "epoch": 1.018202502844141,
      "grad_norm": 2.0709991455078125,
      "learning_rate": 3.3029958285930987e-05,
      "loss": 2.5365,
      "step": 1790
    },
    {
      "epoch": 1.023890784982935,
      "grad_norm": 2.0033340454101562,
      "learning_rate": 3.293515358361775e-05,
      "loss": 2.5303,
      "step": 1800
    },
    {
      "epoch": 1.0295790671217293,
      "grad_norm": 2.0747768878936768,
      "learning_rate": 3.284034888130452e-05,
      "loss": 2.7546,
      "step": 1810
    },
    {
      "epoch": 1.0352673492605233,
      "grad_norm": 1.8816733360290527,
      "learning_rate": 3.2745544178991276e-05,
      "loss": 2.5458,
      "step": 1820
    },
    {
      "epoch": 1.0409556313993173,
      "grad_norm": 2.1635937690734863,
      "learning_rate": 3.2650739476678046e-05,
      "loss": 2.7708,
      "step": 1830
    },
    {
      "epoch": 1.0466439135381116,
      "grad_norm": 2.1173248291015625,
      "learning_rate": 3.255593477436481e-05,
      "loss": 2.724,
      "step": 1840
    },
    {
      "epoch": 1.0523321956769056,
      "grad_norm": 2.0753424167633057,
      "learning_rate": 3.246113007205158e-05,
      "loss": 2.7201,
      "step": 1850
    },
    {
      "epoch": 1.0580204778156996,
      "grad_norm": 1.85474693775177,
      "learning_rate": 3.236632536973834e-05,
      "loss": 2.495,
      "step": 1860
    },
    {
      "epoch": 1.0637087599544937,
      "grad_norm": 1.875768780708313,
      "learning_rate": 3.2271520667425105e-05,
      "loss": 2.5155,
      "step": 1870
    },
    {
      "epoch": 1.069397042093288,
      "grad_norm": 1.9534342288970947,
      "learning_rate": 3.217671596511187e-05,
      "loss": 2.6758,
      "step": 1880
    },
    {
      "epoch": 1.075085324232082,
      "grad_norm": 2.0668601989746094,
      "learning_rate": 3.208191126279864e-05,
      "loss": 2.7611,
      "step": 1890
    },
    {
      "epoch": 1.080773606370876,
      "grad_norm": 1.8663551807403564,
      "learning_rate": 3.19871065604854e-05,
      "loss": 2.3916,
      "step": 1900
    },
    {
      "epoch": 1.0864618885096702,
      "grad_norm": 1.8632152080535889,
      "learning_rate": 3.189230185817217e-05,
      "loss": 2.558,
      "step": 1910
    },
    {
      "epoch": 1.0921501706484642,
      "grad_norm": 2.3884663581848145,
      "learning_rate": 3.179749715585893e-05,
      "loss": 2.8792,
      "step": 1920
    },
    {
      "epoch": 1.0978384527872582,
      "grad_norm": 2.180018901824951,
      "learning_rate": 3.17026924535457e-05,
      "loss": 2.6517,
      "step": 1930
    },
    {
      "epoch": 1.1035267349260522,
      "grad_norm": 1.9802043437957764,
      "learning_rate": 3.160788775123246e-05,
      "loss": 2.465,
      "step": 1940
    },
    {
      "epoch": 1.1092150170648465,
      "grad_norm": 2.2723186016082764,
      "learning_rate": 3.151308304891923e-05,
      "loss": 2.6123,
      "step": 1950
    },
    {
      "epoch": 1.1149032992036405,
      "grad_norm": 1.8655537366867065,
      "learning_rate": 3.1418278346605994e-05,
      "loss": 2.6941,
      "step": 1960
    },
    {
      "epoch": 1.1205915813424345,
      "grad_norm": 1.990998387336731,
      "learning_rate": 3.132347364429276e-05,
      "loss": 2.6446,
      "step": 1970
    },
    {
      "epoch": 1.1262798634812285,
      "grad_norm": 1.9833807945251465,
      "learning_rate": 3.122866894197952e-05,
      "loss": 2.596,
      "step": 1980
    },
    {
      "epoch": 1.1319681456200228,
      "grad_norm": 1.994104027748108,
      "learning_rate": 3.113386423966629e-05,
      "loss": 2.5052,
      "step": 1990
    },
    {
      "epoch": 1.1376564277588168,
      "grad_norm": 2.271852970123291,
      "learning_rate": 3.1039059537353053e-05,
      "loss": 2.509,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5274,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2714021674352640.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
