{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8532423208191127,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005688282138794084,
      "grad_norm": 1.1840522289276123,
      "learning_rate": 4.9905195297686766e-05,
      "loss": 3.6424,
      "step": 10
    },
    {
      "epoch": 0.011376564277588168,
      "grad_norm": 1.1066473722457886,
      "learning_rate": 4.9810390595373535e-05,
      "loss": 3.8112,
      "step": 20
    },
    {
      "epoch": 0.017064846416382253,
      "grad_norm": 1.4943959712982178,
      "learning_rate": 4.97155858930603e-05,
      "loss": 3.7862,
      "step": 30
    },
    {
      "epoch": 0.022753128555176336,
      "grad_norm": 1.267715573310852,
      "learning_rate": 4.962078119074706e-05,
      "loss": 3.2721,
      "step": 40
    },
    {
      "epoch": 0.02844141069397042,
      "grad_norm": 1.2657086849212646,
      "learning_rate": 4.952597648843383e-05,
      "loss": 3.3949,
      "step": 50
    },
    {
      "epoch": 0.034129692832764506,
      "grad_norm": 1.1803443431854248,
      "learning_rate": 4.9431171786120595e-05,
      "loss": 3.2137,
      "step": 60
    },
    {
      "epoch": 0.03981797497155859,
      "grad_norm": 1.294848084449768,
      "learning_rate": 4.933636708380736e-05,
      "loss": 3.1255,
      "step": 70
    },
    {
      "epoch": 0.04550625711035267,
      "grad_norm": 1.0492851734161377,
      "learning_rate": 4.924156238149412e-05,
      "loss": 3.0084,
      "step": 80
    },
    {
      "epoch": 0.051194539249146756,
      "grad_norm": 1.2727558612823486,
      "learning_rate": 4.914675767918089e-05,
      "loss": 3.0637,
      "step": 90
    },
    {
      "epoch": 0.05688282138794084,
      "grad_norm": 1.1558613777160645,
      "learning_rate": 4.9051952976867654e-05,
      "loss": 3.2633,
      "step": 100
    },
    {
      "epoch": 0.06257110352673492,
      "grad_norm": 1.4295926094055176,
      "learning_rate": 4.895714827455442e-05,
      "loss": 3.2033,
      "step": 110
    },
    {
      "epoch": 0.06825938566552901,
      "grad_norm": 1.1814738512039185,
      "learning_rate": 4.886234357224119e-05,
      "loss": 3.1245,
      "step": 120
    },
    {
      "epoch": 0.07394766780432309,
      "grad_norm": 1.2840455770492554,
      "learning_rate": 4.876753886992795e-05,
      "loss": 2.9629,
      "step": 130
    },
    {
      "epoch": 0.07963594994311718,
      "grad_norm": 1.1700204610824585,
      "learning_rate": 4.8672734167614714e-05,
      "loss": 3.2956,
      "step": 140
    },
    {
      "epoch": 0.08532423208191127,
      "grad_norm": 1.3060708045959473,
      "learning_rate": 4.8577929465301484e-05,
      "loss": 2.8537,
      "step": 150
    },
    {
      "epoch": 0.09101251422070535,
      "grad_norm": 1.465187668800354,
      "learning_rate": 4.848312476298825e-05,
      "loss": 3.0538,
      "step": 160
    },
    {
      "epoch": 0.09670079635949944,
      "grad_norm": 1.3654285669326782,
      "learning_rate": 4.838832006067501e-05,
      "loss": 3.3101,
      "step": 170
    },
    {
      "epoch": 0.10238907849829351,
      "grad_norm": 1.361220359802246,
      "learning_rate": 4.829351535836178e-05,
      "loss": 2.9929,
      "step": 180
    },
    {
      "epoch": 0.1080773606370876,
      "grad_norm": 1.4478404521942139,
      "learning_rate": 4.819871065604854e-05,
      "loss": 2.963,
      "step": 190
    },
    {
      "epoch": 0.11376564277588168,
      "grad_norm": 1.507630705833435,
      "learning_rate": 4.8103905953735306e-05,
      "loss": 3.0085,
      "step": 200
    },
    {
      "epoch": 0.11945392491467577,
      "grad_norm": 1.2725622653961182,
      "learning_rate": 4.8009101251422076e-05,
      "loss": 2.9325,
      "step": 210
    },
    {
      "epoch": 0.12514220705346984,
      "grad_norm": 1.3288112878799438,
      "learning_rate": 4.791429654910884e-05,
      "loss": 2.9901,
      "step": 220
    },
    {
      "epoch": 0.13083048919226395,
      "grad_norm": 1.39552903175354,
      "learning_rate": 4.78194918467956e-05,
      "loss": 2.8743,
      "step": 230
    },
    {
      "epoch": 0.13651877133105803,
      "grad_norm": 1.4048992395401,
      "learning_rate": 4.7724687144482366e-05,
      "loss": 2.8956,
      "step": 240
    },
    {
      "epoch": 0.1422070534698521,
      "grad_norm": 1.430892825126648,
      "learning_rate": 4.7629882442169135e-05,
      "loss": 2.937,
      "step": 250
    },
    {
      "epoch": 0.14789533560864618,
      "grad_norm": 1.3461686372756958,
      "learning_rate": 4.75350777398559e-05,
      "loss": 3.1078,
      "step": 260
    },
    {
      "epoch": 0.15358361774744028,
      "grad_norm": 1.4490413665771484,
      "learning_rate": 4.744027303754267e-05,
      "loss": 2.8674,
      "step": 270
    },
    {
      "epoch": 0.15927189988623436,
      "grad_norm": 1.6700984239578247,
      "learning_rate": 4.734546833522943e-05,
      "loss": 3.0276,
      "step": 280
    },
    {
      "epoch": 0.16496018202502843,
      "grad_norm": 1.4937001466751099,
      "learning_rate": 4.7250663632916195e-05,
      "loss": 2.9627,
      "step": 290
    },
    {
      "epoch": 0.17064846416382254,
      "grad_norm": 1.4727190732955933,
      "learning_rate": 4.715585893060296e-05,
      "loss": 2.8063,
      "step": 300
    },
    {
      "epoch": 0.17633674630261661,
      "grad_norm": 1.3600003719329834,
      "learning_rate": 4.706105422828973e-05,
      "loss": 2.6026,
      "step": 310
    },
    {
      "epoch": 0.1820250284414107,
      "grad_norm": 1.5846573114395142,
      "learning_rate": 4.696624952597649e-05,
      "loss": 2.6471,
      "step": 320
    },
    {
      "epoch": 0.18771331058020477,
      "grad_norm": 1.605607509613037,
      "learning_rate": 4.6871444823663254e-05,
      "loss": 2.7449,
      "step": 330
    },
    {
      "epoch": 0.19340159271899887,
      "grad_norm": 1.6549433469772339,
      "learning_rate": 4.6776640121350024e-05,
      "loss": 2.7424,
      "step": 340
    },
    {
      "epoch": 0.19908987485779295,
      "grad_norm": 1.4639432430267334,
      "learning_rate": 4.668183541903679e-05,
      "loss": 2.4782,
      "step": 350
    },
    {
      "epoch": 0.20477815699658702,
      "grad_norm": 1.5364162921905518,
      "learning_rate": 4.658703071672355e-05,
      "loss": 2.8291,
      "step": 360
    },
    {
      "epoch": 0.21046643913538113,
      "grad_norm": 1.5868504047393799,
      "learning_rate": 4.649222601441032e-05,
      "loss": 2.7958,
      "step": 370
    },
    {
      "epoch": 0.2161547212741752,
      "grad_norm": 1.955855131149292,
      "learning_rate": 4.6397421312097084e-05,
      "loss": 2.9948,
      "step": 380
    },
    {
      "epoch": 0.22184300341296928,
      "grad_norm": 1.6161415576934814,
      "learning_rate": 4.630261660978385e-05,
      "loss": 2.807,
      "step": 390
    },
    {
      "epoch": 0.22753128555176336,
      "grad_norm": 1.718761920928955,
      "learning_rate": 4.620781190747061e-05,
      "loss": 2.7385,
      "step": 400
    },
    {
      "epoch": 0.23321956769055746,
      "grad_norm": 1.5597854852676392,
      "learning_rate": 4.611300720515738e-05,
      "loss": 2.7961,
      "step": 410
    },
    {
      "epoch": 0.23890784982935154,
      "grad_norm": 1.6261762380599976,
      "learning_rate": 4.601820250284414e-05,
      "loss": 3.0245,
      "step": 420
    },
    {
      "epoch": 0.2445961319681456,
      "grad_norm": 1.7425310611724854,
      "learning_rate": 4.592339780053091e-05,
      "loss": 2.9694,
      "step": 430
    },
    {
      "epoch": 0.2502844141069397,
      "grad_norm": 1.6412144899368286,
      "learning_rate": 4.5828593098217676e-05,
      "loss": 2.6596,
      "step": 440
    },
    {
      "epoch": 0.25597269624573377,
      "grad_norm": 1.6944148540496826,
      "learning_rate": 4.573378839590444e-05,
      "loss": 2.5412,
      "step": 450
    },
    {
      "epoch": 0.2616609783845279,
      "grad_norm": 1.6538231372833252,
      "learning_rate": 4.56389836935912e-05,
      "loss": 2.5387,
      "step": 460
    },
    {
      "epoch": 0.267349260523322,
      "grad_norm": 1.5119332075119019,
      "learning_rate": 4.554417899127797e-05,
      "loss": 2.8844,
      "step": 470
    },
    {
      "epoch": 0.27303754266211605,
      "grad_norm": 1.8447022438049316,
      "learning_rate": 4.5449374288964735e-05,
      "loss": 2.8867,
      "step": 480
    },
    {
      "epoch": 0.2787258248009101,
      "grad_norm": 1.398255705833435,
      "learning_rate": 4.53545695866515e-05,
      "loss": 2.718,
      "step": 490
    },
    {
      "epoch": 0.2844141069397042,
      "grad_norm": 1.6721446514129639,
      "learning_rate": 4.525976488433826e-05,
      "loss": 2.8587,
      "step": 500
    },
    {
      "epoch": 0.2901023890784983,
      "grad_norm": 1.638363242149353,
      "learning_rate": 4.516496018202503e-05,
      "loss": 2.8962,
      "step": 510
    },
    {
      "epoch": 0.29579067121729236,
      "grad_norm": 1.9011434316635132,
      "learning_rate": 4.5070155479711795e-05,
      "loss": 2.7146,
      "step": 520
    },
    {
      "epoch": 0.3014789533560865,
      "grad_norm": 1.7658836841583252,
      "learning_rate": 4.4975350777398565e-05,
      "loss": 2.609,
      "step": 530
    },
    {
      "epoch": 0.30716723549488056,
      "grad_norm": 1.7144818305969238,
      "learning_rate": 4.488054607508533e-05,
      "loss": 2.711,
      "step": 540
    },
    {
      "epoch": 0.31285551763367464,
      "grad_norm": 1.695155143737793,
      "learning_rate": 4.478574137277209e-05,
      "loss": 2.5638,
      "step": 550
    },
    {
      "epoch": 0.3185437997724687,
      "grad_norm": 1.5457080602645874,
      "learning_rate": 4.4690936670458854e-05,
      "loss": 2.6847,
      "step": 560
    },
    {
      "epoch": 0.3242320819112628,
      "grad_norm": 1.672538161277771,
      "learning_rate": 4.4596131968145624e-05,
      "loss": 2.6473,
      "step": 570
    },
    {
      "epoch": 0.32992036405005687,
      "grad_norm": 1.5833854675292969,
      "learning_rate": 4.450132726583239e-05,
      "loss": 2.645,
      "step": 580
    },
    {
      "epoch": 0.33560864618885095,
      "grad_norm": 1.7899351119995117,
      "learning_rate": 4.440652256351916e-05,
      "loss": 2.7977,
      "step": 590
    },
    {
      "epoch": 0.3412969283276451,
      "grad_norm": 1.5812206268310547,
      "learning_rate": 4.431171786120592e-05,
      "loss": 2.4875,
      "step": 600
    },
    {
      "epoch": 0.34698521046643915,
      "grad_norm": 1.52481210231781,
      "learning_rate": 4.4216913158892684e-05,
      "loss": 2.5622,
      "step": 610
    },
    {
      "epoch": 0.35267349260523323,
      "grad_norm": 1.5895038843154907,
      "learning_rate": 4.412210845657945e-05,
      "loss": 2.5312,
      "step": 620
    },
    {
      "epoch": 0.3583617747440273,
      "grad_norm": 1.4821257591247559,
      "learning_rate": 4.402730375426622e-05,
      "loss": 2.9617,
      "step": 630
    },
    {
      "epoch": 0.3640500568828214,
      "grad_norm": 1.8058371543884277,
      "learning_rate": 4.393249905195298e-05,
      "loss": 2.5655,
      "step": 640
    },
    {
      "epoch": 0.36973833902161546,
      "grad_norm": 1.7320345640182495,
      "learning_rate": 4.383769434963974e-05,
      "loss": 2.6786,
      "step": 650
    },
    {
      "epoch": 0.37542662116040953,
      "grad_norm": 1.8239275217056274,
      "learning_rate": 4.3742889647326506e-05,
      "loss": 2.6282,
      "step": 660
    },
    {
      "epoch": 0.38111490329920367,
      "grad_norm": 1.6258221864700317,
      "learning_rate": 4.3648084945013276e-05,
      "loss": 2.4673,
      "step": 670
    },
    {
      "epoch": 0.38680318543799774,
      "grad_norm": 1.7344262599945068,
      "learning_rate": 4.355328024270004e-05,
      "loss": 2.6889,
      "step": 680
    },
    {
      "epoch": 0.3924914675767918,
      "grad_norm": 1.7352560758590698,
      "learning_rate": 4.345847554038681e-05,
      "loss": 2.6415,
      "step": 690
    },
    {
      "epoch": 0.3981797497155859,
      "grad_norm": 1.6515235900878906,
      "learning_rate": 4.336367083807357e-05,
      "loss": 2.6934,
      "step": 700
    },
    {
      "epoch": 0.40386803185437997,
      "grad_norm": 1.7131084203720093,
      "learning_rate": 4.3268866135760335e-05,
      "loss": 2.5069,
      "step": 710
    },
    {
      "epoch": 0.40955631399317405,
      "grad_norm": 2.0305275917053223,
      "learning_rate": 4.31740614334471e-05,
      "loss": 2.604,
      "step": 720
    },
    {
      "epoch": 0.4152445961319681,
      "grad_norm": 4.964780330657959,
      "learning_rate": 4.307925673113387e-05,
      "loss": 2.9609,
      "step": 730
    },
    {
      "epoch": 0.42093287827076226,
      "grad_norm": 1.7239235639572144,
      "learning_rate": 4.298445202882063e-05,
      "loss": 2.993,
      "step": 740
    },
    {
      "epoch": 0.42662116040955633,
      "grad_norm": 1.4889949560165405,
      "learning_rate": 4.28896473265074e-05,
      "loss": 2.5141,
      "step": 750
    },
    {
      "epoch": 0.4323094425483504,
      "grad_norm": 1.940831184387207,
      "learning_rate": 4.2794842624194165e-05,
      "loss": 2.8515,
      "step": 760
    },
    {
      "epoch": 0.4379977246871445,
      "grad_norm": 1.6206830739974976,
      "learning_rate": 4.270003792188093e-05,
      "loss": 2.7304,
      "step": 770
    },
    {
      "epoch": 0.44368600682593856,
      "grad_norm": 1.480495572090149,
      "learning_rate": 4.260523321956769e-05,
      "loss": 2.5623,
      "step": 780
    },
    {
      "epoch": 0.44937428896473264,
      "grad_norm": 1.7047971487045288,
      "learning_rate": 4.251042851725446e-05,
      "loss": 2.5435,
      "step": 790
    },
    {
      "epoch": 0.4550625711035267,
      "grad_norm": 1.8817979097366333,
      "learning_rate": 4.2415623814941224e-05,
      "loss": 2.6949,
      "step": 800
    },
    {
      "epoch": 0.46075085324232085,
      "grad_norm": 1.8404712677001953,
      "learning_rate": 4.2320819112627994e-05,
      "loss": 2.4677,
      "step": 810
    },
    {
      "epoch": 0.4664391353811149,
      "grad_norm": 1.7871347665786743,
      "learning_rate": 4.222601441031475e-05,
      "loss": 2.8546,
      "step": 820
    },
    {
      "epoch": 0.472127417519909,
      "grad_norm": 1.636745572090149,
      "learning_rate": 4.213120970800152e-05,
      "loss": 2.6887,
      "step": 830
    },
    {
      "epoch": 0.4778156996587031,
      "grad_norm": 1.7996717691421509,
      "learning_rate": 4.2036405005688284e-05,
      "loss": 2.581,
      "step": 840
    },
    {
      "epoch": 0.48350398179749715,
      "grad_norm": 1.8387221097946167,
      "learning_rate": 4.1941600303375053e-05,
      "loss": 2.9209,
      "step": 850
    },
    {
      "epoch": 0.4891922639362912,
      "grad_norm": 1.9100065231323242,
      "learning_rate": 4.184679560106182e-05,
      "loss": 2.4763,
      "step": 860
    },
    {
      "epoch": 0.4948805460750853,
      "grad_norm": 1.6824121475219727,
      "learning_rate": 4.175199089874858e-05,
      "loss": 2.8989,
      "step": 870
    },
    {
      "epoch": 0.5005688282138794,
      "grad_norm": 1.6961688995361328,
      "learning_rate": 4.165718619643534e-05,
      "loss": 2.6392,
      "step": 880
    },
    {
      "epoch": 0.5062571103526735,
      "grad_norm": 1.7537975311279297,
      "learning_rate": 4.156238149412211e-05,
      "loss": 2.662,
      "step": 890
    },
    {
      "epoch": 0.5119453924914675,
      "grad_norm": 1.7135173082351685,
      "learning_rate": 4.1467576791808876e-05,
      "loss": 2.7814,
      "step": 900
    },
    {
      "epoch": 0.5176336746302617,
      "grad_norm": 1.93651282787323,
      "learning_rate": 4.1372772089495646e-05,
      "loss": 2.5821,
      "step": 910
    },
    {
      "epoch": 0.5233219567690558,
      "grad_norm": 1.6874661445617676,
      "learning_rate": 4.12779673871824e-05,
      "loss": 2.6731,
      "step": 920
    },
    {
      "epoch": 0.5290102389078498,
      "grad_norm": 1.9278578758239746,
      "learning_rate": 4.118316268486917e-05,
      "loss": 2.4643,
      "step": 930
    },
    {
      "epoch": 0.534698521046644,
      "grad_norm": 2.033489465713501,
      "learning_rate": 4.1088357982555935e-05,
      "loss": 2.6064,
      "step": 940
    },
    {
      "epoch": 0.540386803185438,
      "grad_norm": 1.6602821350097656,
      "learning_rate": 4.0993553280242705e-05,
      "loss": 2.6248,
      "step": 950
    },
    {
      "epoch": 0.5460750853242321,
      "grad_norm": 1.8129944801330566,
      "learning_rate": 4.089874857792947e-05,
      "loss": 2.6789,
      "step": 960
    },
    {
      "epoch": 0.5517633674630261,
      "grad_norm": 1.7531323432922363,
      "learning_rate": 4.080394387561624e-05,
      "loss": 2.6559,
      "step": 970
    },
    {
      "epoch": 0.5574516496018203,
      "grad_norm": 1.7522550821304321,
      "learning_rate": 4.0709139173302995e-05,
      "loss": 2.6144,
      "step": 980
    },
    {
      "epoch": 0.5631399317406144,
      "grad_norm": 1.7209596633911133,
      "learning_rate": 4.0614334470989765e-05,
      "loss": 2.456,
      "step": 990
    },
    {
      "epoch": 0.5688282138794084,
      "grad_norm": 1.9101529121398926,
      "learning_rate": 4.051952976867653e-05,
      "loss": 2.5947,
      "step": 1000
    },
    {
      "epoch": 0.5745164960182025,
      "grad_norm": 1.9122183322906494,
      "learning_rate": 4.04247250663633e-05,
      "loss": 2.7778,
      "step": 1010
    },
    {
      "epoch": 0.5802047781569966,
      "grad_norm": 1.9505305290222168,
      "learning_rate": 4.032992036405006e-05,
      "loss": 2.6444,
      "step": 1020
    },
    {
      "epoch": 0.5858930602957907,
      "grad_norm": 1.8624544143676758,
      "learning_rate": 4.0235115661736824e-05,
      "loss": 2.6672,
      "step": 1030
    },
    {
      "epoch": 0.5915813424345847,
      "grad_norm": 1.763140082359314,
      "learning_rate": 4.014031095942359e-05,
      "loss": 2.4806,
      "step": 1040
    },
    {
      "epoch": 0.5972696245733788,
      "grad_norm": 1.7116060256958008,
      "learning_rate": 4.004550625711036e-05,
      "loss": 2.7785,
      "step": 1050
    },
    {
      "epoch": 0.602957906712173,
      "grad_norm": 1.7877191305160522,
      "learning_rate": 3.995070155479712e-05,
      "loss": 2.5715,
      "step": 1060
    },
    {
      "epoch": 0.608646188850967,
      "grad_norm": 1.8293726444244385,
      "learning_rate": 3.985589685248389e-05,
      "loss": 2.434,
      "step": 1070
    },
    {
      "epoch": 0.6143344709897611,
      "grad_norm": 2.2948577404022217,
      "learning_rate": 3.976109215017065e-05,
      "loss": 2.5195,
      "step": 1080
    },
    {
      "epoch": 0.6200227531285551,
      "grad_norm": 1.8122014999389648,
      "learning_rate": 3.966628744785742e-05,
      "loss": 2.4367,
      "step": 1090
    },
    {
      "epoch": 0.6257110352673493,
      "grad_norm": 1.742236852645874,
      "learning_rate": 3.957148274554418e-05,
      "loss": 2.6192,
      "step": 1100
    },
    {
      "epoch": 0.6313993174061433,
      "grad_norm": 2.0351133346557617,
      "learning_rate": 3.947667804323095e-05,
      "loss": 2.3937,
      "step": 1110
    },
    {
      "epoch": 0.6370875995449374,
      "grad_norm": 1.8651484251022339,
      "learning_rate": 3.938187334091771e-05,
      "loss": 2.6671,
      "step": 1120
    },
    {
      "epoch": 0.6427758816837316,
      "grad_norm": 1.8781979084014893,
      "learning_rate": 3.9287068638604476e-05,
      "loss": 2.6756,
      "step": 1130
    },
    {
      "epoch": 0.6484641638225256,
      "grad_norm": 2.0190937519073486,
      "learning_rate": 3.919226393629124e-05,
      "loss": 2.5421,
      "step": 1140
    },
    {
      "epoch": 0.6541524459613197,
      "grad_norm": 1.8050549030303955,
      "learning_rate": 3.909745923397801e-05,
      "loss": 2.6385,
      "step": 1150
    },
    {
      "epoch": 0.6598407281001137,
      "grad_norm": 2.2315075397491455,
      "learning_rate": 3.900265453166477e-05,
      "loss": 2.5708,
      "step": 1160
    },
    {
      "epoch": 0.6655290102389079,
      "grad_norm": 1.8540414571762085,
      "learning_rate": 3.890784982935154e-05,
      "loss": 2.435,
      "step": 1170
    },
    {
      "epoch": 0.6712172923777019,
      "grad_norm": 1.91741943359375,
      "learning_rate": 3.8813045127038305e-05,
      "loss": 2.6624,
      "step": 1180
    },
    {
      "epoch": 0.676905574516496,
      "grad_norm": 2.1156845092773438,
      "learning_rate": 3.871824042472507e-05,
      "loss": 2.5729,
      "step": 1190
    },
    {
      "epoch": 0.6825938566552902,
      "grad_norm": 1.7722679376602173,
      "learning_rate": 3.862343572241183e-05,
      "loss": 2.6359,
      "step": 1200
    },
    {
      "epoch": 0.6882821387940842,
      "grad_norm": 1.753456473350525,
      "learning_rate": 3.85286310200986e-05,
      "loss": 2.7055,
      "step": 1210
    },
    {
      "epoch": 0.6939704209328783,
      "grad_norm": 2.026064395904541,
      "learning_rate": 3.8433826317785365e-05,
      "loss": 3.0982,
      "step": 1220
    },
    {
      "epoch": 0.6996587030716723,
      "grad_norm": 1.8876149654388428,
      "learning_rate": 3.8339021615472135e-05,
      "loss": 2.6649,
      "step": 1230
    },
    {
      "epoch": 0.7053469852104665,
      "grad_norm": 1.433695912361145,
      "learning_rate": 3.824421691315889e-05,
      "loss": 2.6315,
      "step": 1240
    },
    {
      "epoch": 0.7110352673492605,
      "grad_norm": 1.8294188976287842,
      "learning_rate": 3.814941221084566e-05,
      "loss": 2.3983,
      "step": 1250
    },
    {
      "epoch": 0.7167235494880546,
      "grad_norm": 1.8802483081817627,
      "learning_rate": 3.8054607508532424e-05,
      "loss": 2.5432,
      "step": 1260
    },
    {
      "epoch": 0.7224118316268487,
      "grad_norm": 1.991202473640442,
      "learning_rate": 3.7959802806219194e-05,
      "loss": 2.6204,
      "step": 1270
    },
    {
      "epoch": 0.7281001137656428,
      "grad_norm": 1.7331645488739014,
      "learning_rate": 3.786499810390596e-05,
      "loss": 2.5238,
      "step": 1280
    },
    {
      "epoch": 0.7337883959044369,
      "grad_norm": 2.018613815307617,
      "learning_rate": 3.777019340159272e-05,
      "loss": 2.3684,
      "step": 1290
    },
    {
      "epoch": 0.7394766780432309,
      "grad_norm": 1.7485496997833252,
      "learning_rate": 3.7675388699279484e-05,
      "loss": 2.6712,
      "step": 1300
    },
    {
      "epoch": 0.745164960182025,
      "grad_norm": 1.8774378299713135,
      "learning_rate": 3.7580583996966253e-05,
      "loss": 2.4982,
      "step": 1310
    },
    {
      "epoch": 0.7508532423208191,
      "grad_norm": 1.839454174041748,
      "learning_rate": 3.7485779294653017e-05,
      "loss": 2.6664,
      "step": 1320
    },
    {
      "epoch": 0.7565415244596132,
      "grad_norm": 1.7456144094467163,
      "learning_rate": 3.7390974592339787e-05,
      "loss": 2.6015,
      "step": 1330
    },
    {
      "epoch": 0.7622298065984073,
      "grad_norm": 1.8833580017089844,
      "learning_rate": 3.729616989002654e-05,
      "loss": 2.4818,
      "step": 1340
    },
    {
      "epoch": 0.7679180887372014,
      "grad_norm": 2.1328296661376953,
      "learning_rate": 3.720136518771331e-05,
      "loss": 2.2225,
      "step": 1350
    },
    {
      "epoch": 0.7736063708759955,
      "grad_norm": 1.946182370185852,
      "learning_rate": 3.7106560485400076e-05,
      "loss": 2.4492,
      "step": 1360
    },
    {
      "epoch": 0.7792946530147895,
      "grad_norm": 1.7089473009109497,
      "learning_rate": 3.7011755783086846e-05,
      "loss": 2.6642,
      "step": 1370
    },
    {
      "epoch": 0.7849829351535836,
      "grad_norm": 1.9546905755996704,
      "learning_rate": 3.691695108077361e-05,
      "loss": 2.5189,
      "step": 1380
    },
    {
      "epoch": 0.7906712172923777,
      "grad_norm": 1.945075511932373,
      "learning_rate": 3.682214637846038e-05,
      "loss": 2.6082,
      "step": 1390
    },
    {
      "epoch": 0.7963594994311718,
      "grad_norm": 2.08254075050354,
      "learning_rate": 3.6727341676147135e-05,
      "loss": 2.5183,
      "step": 1400
    },
    {
      "epoch": 0.8020477815699659,
      "grad_norm": 1.7358146905899048,
      "learning_rate": 3.6632536973833905e-05,
      "loss": 2.3719,
      "step": 1410
    },
    {
      "epoch": 0.8077360637087599,
      "grad_norm": 2.394360303878784,
      "learning_rate": 3.653773227152067e-05,
      "loss": 2.6006,
      "step": 1420
    },
    {
      "epoch": 0.8134243458475541,
      "grad_norm": 2.1957759857177734,
      "learning_rate": 3.644292756920744e-05,
      "loss": 2.7562,
      "step": 1430
    },
    {
      "epoch": 0.8191126279863481,
      "grad_norm": 1.7685041427612305,
      "learning_rate": 3.63481228668942e-05,
      "loss": 2.2255,
      "step": 1440
    },
    {
      "epoch": 0.8248009101251422,
      "grad_norm": 1.9511439800262451,
      "learning_rate": 3.6253318164580965e-05,
      "loss": 2.5052,
      "step": 1450
    },
    {
      "epoch": 0.8304891922639362,
      "grad_norm": 1.850136399269104,
      "learning_rate": 3.615851346226773e-05,
      "loss": 2.4598,
      "step": 1460
    },
    {
      "epoch": 0.8361774744027304,
      "grad_norm": 2.1229028701782227,
      "learning_rate": 3.60637087599545e-05,
      "loss": 2.6601,
      "step": 1470
    },
    {
      "epoch": 0.8418657565415245,
      "grad_norm": 2.146454334259033,
      "learning_rate": 3.596890405764126e-05,
      "loss": 2.6687,
      "step": 1480
    },
    {
      "epoch": 0.8475540386803185,
      "grad_norm": 2.2313992977142334,
      "learning_rate": 3.587409935532803e-05,
      "loss": 2.6986,
      "step": 1490
    },
    {
      "epoch": 0.8532423208191127,
      "grad_norm": 1.8351048231124878,
      "learning_rate": 3.577929465301479e-05,
      "loss": 2.7693,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5274,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2036025262080000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
