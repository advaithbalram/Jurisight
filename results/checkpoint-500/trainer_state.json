{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.2844141069397042,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005688282138794084,
      "grad_norm": 1.1840522289276123,
      "learning_rate": 4.9905195297686766e-05,
      "loss": 3.6424,
      "step": 10
    },
    {
      "epoch": 0.011376564277588168,
      "grad_norm": 1.1066473722457886,
      "learning_rate": 4.9810390595373535e-05,
      "loss": 3.8112,
      "step": 20
    },
    {
      "epoch": 0.017064846416382253,
      "grad_norm": 1.4943959712982178,
      "learning_rate": 4.97155858930603e-05,
      "loss": 3.7862,
      "step": 30
    },
    {
      "epoch": 0.022753128555176336,
      "grad_norm": 1.267715573310852,
      "learning_rate": 4.962078119074706e-05,
      "loss": 3.2721,
      "step": 40
    },
    {
      "epoch": 0.02844141069397042,
      "grad_norm": 1.2657086849212646,
      "learning_rate": 4.952597648843383e-05,
      "loss": 3.3949,
      "step": 50
    },
    {
      "epoch": 0.034129692832764506,
      "grad_norm": 1.1803443431854248,
      "learning_rate": 4.9431171786120595e-05,
      "loss": 3.2137,
      "step": 60
    },
    {
      "epoch": 0.03981797497155859,
      "grad_norm": 1.294848084449768,
      "learning_rate": 4.933636708380736e-05,
      "loss": 3.1255,
      "step": 70
    },
    {
      "epoch": 0.04550625711035267,
      "grad_norm": 1.0492851734161377,
      "learning_rate": 4.924156238149412e-05,
      "loss": 3.0084,
      "step": 80
    },
    {
      "epoch": 0.051194539249146756,
      "grad_norm": 1.2727558612823486,
      "learning_rate": 4.914675767918089e-05,
      "loss": 3.0637,
      "step": 90
    },
    {
      "epoch": 0.05688282138794084,
      "grad_norm": 1.1558613777160645,
      "learning_rate": 4.9051952976867654e-05,
      "loss": 3.2633,
      "step": 100
    },
    {
      "epoch": 0.06257110352673492,
      "grad_norm": 1.4295926094055176,
      "learning_rate": 4.895714827455442e-05,
      "loss": 3.2033,
      "step": 110
    },
    {
      "epoch": 0.06825938566552901,
      "grad_norm": 1.1814738512039185,
      "learning_rate": 4.886234357224119e-05,
      "loss": 3.1245,
      "step": 120
    },
    {
      "epoch": 0.07394766780432309,
      "grad_norm": 1.2840455770492554,
      "learning_rate": 4.876753886992795e-05,
      "loss": 2.9629,
      "step": 130
    },
    {
      "epoch": 0.07963594994311718,
      "grad_norm": 1.1700204610824585,
      "learning_rate": 4.8672734167614714e-05,
      "loss": 3.2956,
      "step": 140
    },
    {
      "epoch": 0.08532423208191127,
      "grad_norm": 1.3060708045959473,
      "learning_rate": 4.8577929465301484e-05,
      "loss": 2.8537,
      "step": 150
    },
    {
      "epoch": 0.09101251422070535,
      "grad_norm": 1.465187668800354,
      "learning_rate": 4.848312476298825e-05,
      "loss": 3.0538,
      "step": 160
    },
    {
      "epoch": 0.09670079635949944,
      "grad_norm": 1.3654285669326782,
      "learning_rate": 4.838832006067501e-05,
      "loss": 3.3101,
      "step": 170
    },
    {
      "epoch": 0.10238907849829351,
      "grad_norm": 1.361220359802246,
      "learning_rate": 4.829351535836178e-05,
      "loss": 2.9929,
      "step": 180
    },
    {
      "epoch": 0.1080773606370876,
      "grad_norm": 1.4478404521942139,
      "learning_rate": 4.819871065604854e-05,
      "loss": 2.963,
      "step": 190
    },
    {
      "epoch": 0.11376564277588168,
      "grad_norm": 1.507630705833435,
      "learning_rate": 4.8103905953735306e-05,
      "loss": 3.0085,
      "step": 200
    },
    {
      "epoch": 0.11945392491467577,
      "grad_norm": 1.2725622653961182,
      "learning_rate": 4.8009101251422076e-05,
      "loss": 2.9325,
      "step": 210
    },
    {
      "epoch": 0.12514220705346984,
      "grad_norm": 1.3288112878799438,
      "learning_rate": 4.791429654910884e-05,
      "loss": 2.9901,
      "step": 220
    },
    {
      "epoch": 0.13083048919226395,
      "grad_norm": 1.39552903175354,
      "learning_rate": 4.78194918467956e-05,
      "loss": 2.8743,
      "step": 230
    },
    {
      "epoch": 0.13651877133105803,
      "grad_norm": 1.4048992395401,
      "learning_rate": 4.7724687144482366e-05,
      "loss": 2.8956,
      "step": 240
    },
    {
      "epoch": 0.1422070534698521,
      "grad_norm": 1.430892825126648,
      "learning_rate": 4.7629882442169135e-05,
      "loss": 2.937,
      "step": 250
    },
    {
      "epoch": 0.14789533560864618,
      "grad_norm": 1.3461686372756958,
      "learning_rate": 4.75350777398559e-05,
      "loss": 3.1078,
      "step": 260
    },
    {
      "epoch": 0.15358361774744028,
      "grad_norm": 1.4490413665771484,
      "learning_rate": 4.744027303754267e-05,
      "loss": 2.8674,
      "step": 270
    },
    {
      "epoch": 0.15927189988623436,
      "grad_norm": 1.6700984239578247,
      "learning_rate": 4.734546833522943e-05,
      "loss": 3.0276,
      "step": 280
    },
    {
      "epoch": 0.16496018202502843,
      "grad_norm": 1.4937001466751099,
      "learning_rate": 4.7250663632916195e-05,
      "loss": 2.9627,
      "step": 290
    },
    {
      "epoch": 0.17064846416382254,
      "grad_norm": 1.4727190732955933,
      "learning_rate": 4.715585893060296e-05,
      "loss": 2.8063,
      "step": 300
    },
    {
      "epoch": 0.17633674630261661,
      "grad_norm": 1.3600003719329834,
      "learning_rate": 4.706105422828973e-05,
      "loss": 2.6026,
      "step": 310
    },
    {
      "epoch": 0.1820250284414107,
      "grad_norm": 1.5846573114395142,
      "learning_rate": 4.696624952597649e-05,
      "loss": 2.6471,
      "step": 320
    },
    {
      "epoch": 0.18771331058020477,
      "grad_norm": 1.605607509613037,
      "learning_rate": 4.6871444823663254e-05,
      "loss": 2.7449,
      "step": 330
    },
    {
      "epoch": 0.19340159271899887,
      "grad_norm": 1.6549433469772339,
      "learning_rate": 4.6776640121350024e-05,
      "loss": 2.7424,
      "step": 340
    },
    {
      "epoch": 0.19908987485779295,
      "grad_norm": 1.4639432430267334,
      "learning_rate": 4.668183541903679e-05,
      "loss": 2.4782,
      "step": 350
    },
    {
      "epoch": 0.20477815699658702,
      "grad_norm": 1.5364162921905518,
      "learning_rate": 4.658703071672355e-05,
      "loss": 2.8291,
      "step": 360
    },
    {
      "epoch": 0.21046643913538113,
      "grad_norm": 1.5868504047393799,
      "learning_rate": 4.649222601441032e-05,
      "loss": 2.7958,
      "step": 370
    },
    {
      "epoch": 0.2161547212741752,
      "grad_norm": 1.955855131149292,
      "learning_rate": 4.6397421312097084e-05,
      "loss": 2.9948,
      "step": 380
    },
    {
      "epoch": 0.22184300341296928,
      "grad_norm": 1.6161415576934814,
      "learning_rate": 4.630261660978385e-05,
      "loss": 2.807,
      "step": 390
    },
    {
      "epoch": 0.22753128555176336,
      "grad_norm": 1.718761920928955,
      "learning_rate": 4.620781190747061e-05,
      "loss": 2.7385,
      "step": 400
    },
    {
      "epoch": 0.23321956769055746,
      "grad_norm": 1.5597854852676392,
      "learning_rate": 4.611300720515738e-05,
      "loss": 2.7961,
      "step": 410
    },
    {
      "epoch": 0.23890784982935154,
      "grad_norm": 1.6261762380599976,
      "learning_rate": 4.601820250284414e-05,
      "loss": 3.0245,
      "step": 420
    },
    {
      "epoch": 0.2445961319681456,
      "grad_norm": 1.7425310611724854,
      "learning_rate": 4.592339780053091e-05,
      "loss": 2.9694,
      "step": 430
    },
    {
      "epoch": 0.2502844141069397,
      "grad_norm": 1.6412144899368286,
      "learning_rate": 4.5828593098217676e-05,
      "loss": 2.6596,
      "step": 440
    },
    {
      "epoch": 0.25597269624573377,
      "grad_norm": 1.6944148540496826,
      "learning_rate": 4.573378839590444e-05,
      "loss": 2.5412,
      "step": 450
    },
    {
      "epoch": 0.2616609783845279,
      "grad_norm": 1.6538231372833252,
      "learning_rate": 4.56389836935912e-05,
      "loss": 2.5387,
      "step": 460
    },
    {
      "epoch": 0.267349260523322,
      "grad_norm": 1.5119332075119019,
      "learning_rate": 4.554417899127797e-05,
      "loss": 2.8844,
      "step": 470
    },
    {
      "epoch": 0.27303754266211605,
      "grad_norm": 1.8447022438049316,
      "learning_rate": 4.5449374288964735e-05,
      "loss": 2.8867,
      "step": 480
    },
    {
      "epoch": 0.2787258248009101,
      "grad_norm": 1.398255705833435,
      "learning_rate": 4.53545695866515e-05,
      "loss": 2.718,
      "step": 490
    },
    {
      "epoch": 0.2844141069397042,
      "grad_norm": 1.6721446514129639,
      "learning_rate": 4.525976488433826e-05,
      "loss": 2.8587,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5274,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 678675087360000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
